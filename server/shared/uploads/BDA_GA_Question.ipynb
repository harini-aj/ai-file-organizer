{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "260b8eab",
   "metadata": {
    "id": "260b8eab"
   },
   "source": [
    "### BiG Data Analytics : Greaded Assesment  ( 20 Marks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6974d1b0",
   "metadata": {
    "id": "6974d1b0"
   },
   "source": [
    "#### Instructions :\n",
    "\n",
    "- The solution  notebook should idealy has to be run inside the DataBricks community edition and excuted solution should be svaed as .html file.  (File>Export> HTML)\n",
    "\n",
    "- Ensure notebook is executed without any error and all excuted- cell output sholuld be clearly visible  in the  saved/uploaded (.html) file'.\n",
    "\n",
    "\n",
    "- However, If students has Spark setup inside their local system (with jupyter notebook)  they can execute the solution locally also. Excuted solution should be svaed as .html file and Ensure notebook is executed without any error and all excuted- cell output sholuld be clearly visible  in the  saved/uploaded (.html) file. (File>Download as>.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245816bd",
   "metadata": {
    "id": "245816bd"
   },
   "source": [
    "#### DataSet : Mumbai.csv\n",
    "\n",
    "Housing dataset of India's financial capital is provided. \n",
    "Dataset contains, collection of prices of new and resale houses located in the Mumbai and the amenities provided with each house.\n",
    "\n",
    "Process the dataset as questioned below using spark libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f364503",
   "metadata": {
    "id": "4f364503"
   },
   "outputs": [],
   "source": [
    "# import statements\n",
    " \n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ae53c9",
   "metadata": {
    "id": "d0ae53c9"
   },
   "source": [
    "####  Create Spark Session  & Load the  provided dataset into  spark-dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b5cb00",
   "metadata": {
    "id": "a1b5cb00"
   },
   "outputs": [],
   "source": [
    "### If excuting in localdatabrics community edition\n",
    "## load the Mumbai.csv inside databrics community edition  and  Use this code while excuting in databrics community edition \n",
    "# #Note : in databricks community edition : \n",
    "\n",
    "# # reference code to load in databrics \n",
    "# # File location and type\n",
    "# file_location = \"/FileStore/tables/Mumbai.csv\"\n",
    "# file_type = \"csv\"\n",
    "\n",
    "# # CSV options\n",
    "# infer_schema = \"True\"\n",
    "# first_row_is_header = \"True\"\n",
    "# delimiter = \",\"\n",
    "\n",
    "# # The applied options are for CSV files. For other file types, these will be ignored.\n",
    "# df = spark.read.format(file_type) \\\n",
    "#   .option(\"inferSchema\", infer_schema) \\\n",
    "#   .option(\"header\", first_row_is_header) \\\n",
    "#   .option(\"sep\", delimiter) \\\n",
    "#   .load(file_location)\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf83eaf",
   "metadata": {
    "id": "9bf83eaf"
   },
   "outputs": [],
   "source": [
    "# #  if excuting in local\n",
    "# sc = SparkContext.getOrCreate()\n",
    "# spark = SparkSession(sc) \n",
    "# file_path='file:///write _absolute_path _of_Mumbai.csv' \n",
    "\n",
    "# df=spark.read.format(\"csv\").option(\"header\", \"True\").option(\"inferschema\",\"True\").load(file_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d9a3df",
   "metadata": {
    "id": "00d9a3df"
   },
   "source": [
    "#### 1. Show/print  schema of the dataframe  (1 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6293e450",
   "metadata": {
    "id": "6293e450"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66c88197",
   "metadata": {
    "id": "66c88197"
   },
   "source": [
    "#### 2. Delete  the column - \"No. of Bedrooms\"  from the spark dataframe ( 1 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0544eb",
   "metadata": {
    "id": "4d0544eb"
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068edccb",
   "metadata": {
    "id": "068edccb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be09992e",
   "metadata": {
    "id": "be09992e"
   },
   "source": [
    "#### 3. Convert string column (i.e. \"Location)  into numeric values using StringIndexer transformer and make sure now DataFrame does not have any string columns anymore. (3marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a9ee5c",
   "metadata": {
    "id": "06a9ee5c"
   },
   "outputs": [],
   "source": [
    "# use below StringIndexer method  \n",
    "# indexer_model = StringIndexer(inputCols = [\"Location\"],outputCols =[\"Location_indexed\"]).fit(df)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ab403b",
   "metadata": {
    "id": "37ab403b"
   },
   "source": [
    "#### 4. Using vectorAssembler combines all columns (except target column i.e. 'Price') of spark DataFrame into single column (named as features). Make sure DataFrame now contains only two columns features and price. (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d21cd",
   "metadata": {
    "id": "252d21cd"
   },
   "outputs": [],
   "source": [
    "# # use below VectorAssembler method \n",
    "# features_col = df_indexed.columns\n",
    "# features_col.remove('Price')\n",
    "# assembler = VectorAssembler(inputCols= features_col, outputCol= \"features\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3e168c",
   "metadata": {
    "id": "2b3e168c"
   },
   "source": [
    "#### 5. Scale the data using StandardScaler. The input columns are the features, and the output column with the rescaled that will be included in the scaled_df will be named \"features_scaled\". (3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b6fa04",
   "metadata": {
    "id": "f1b6fa04"
   },
   "outputs": [],
   "source": [
    "# #  use below standardScaler method \n",
    "# standardScaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532f13e",
   "metadata": {
    "id": "2532f13e"
   },
   "source": [
    "#### 6.  Split the vectorised dataframe into training and test sets with approx one third records being held for testing  (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ee0009",
   "metadata": {
    "id": "20ee0009"
   },
   "outputs": [],
   "source": [
    "# use randomSplit method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a652a71",
   "metadata": {
    "id": "1a652a71"
   },
   "source": [
    "#### 7.. Build the LinerRegression object 'lr' by setting the required parameters. (3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787edfee",
   "metadata": {
    "id": "787edfee"
   },
   "outputs": [],
   "source": [
    "# use below LinerRegression method\n",
    "#lr = LinearRegression(featuresCol=\"features_scaled\", labelCol=\"Price\")\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d4e85d",
   "metadata": {
    "id": "77d4e85d"
   },
   "source": [
    "#### 8. Find rmse of trained LinearRegression model on test set (3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4b028a",
   "metadata": {
    "id": "0e4b028a"
   },
   "outputs": [],
   "source": [
    "# use below RegressionEvaluator method\n",
    "#evaluator = RegressionEvaluator(labelCol=\"Price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
